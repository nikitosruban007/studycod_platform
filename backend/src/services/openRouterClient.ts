import fetch from 'node-fetch';
import { pickOpenRouterKey } from './openRouterKeys';

export interface OpenRouterRequest {
  model: string;
  messages: Array<{ role: string; content: string }>;
  response_format?: { type: string };
  temperature?: number;
  max_tokens?: number;
}

export interface OpenRouterResponse {
  id?: string;
  choices?: Array<{
    message?: {
      content?: string;
    };
  }>;
  error?: {
    message?: string;
    type?: string;
  };
}

export interface OpenRouterCallOptions {
  timeout?: number;
  maxRetries?: number;
  userId?: number;
  topicId?: number;
  traceId?: string;
}

function modelsWithoutSystemSupport(): string[] {
  return [
    'google/gemma-3-27b-it',
    'google/gemma-3-27b-it:free',
  ];
}

function modelsWithoutJsonMode(): string[] {
  return [
    'google/gemma-3-27b-it',
    'google/gemma-3-27b-it:free',
  ];
}

function normalizeModelForSystemCheck(model: string): string {
  return model.toLowerCase().trim();
}

function shouldCombineSystemToUser(model: string): boolean {
  const normalized = normalizeModelForSystemCheck(model);
  return modelsWithoutSystemSupport().some(m => normalized.includes(m.toLowerCase()));
}

function shouldRemoveJsonMode(model: string): boolean {
  const normalized = normalizeModelForSystemCheck(model);
  return modelsWithoutJsonMode().some(m => normalized.includes(m.toLowerCase()));
}

function adaptMessagesForModel(messages: Array<{ role: string; content: string }>, model: string): Array<{ role: string; content: string }> {
  if (!shouldCombineSystemToUser(model)) {
    return messages;
  }

  const systemMessages: string[] = [];
  const userMessages: string[] = [];

  for (const msg of messages) {
    if (msg.role === 'system' || msg.role === 'developer') {
      systemMessages.push(msg.content);
    } else if (msg.role === 'user') {
      userMessages.push(msg.content);
    }
  }

  if (systemMessages.length === 0) {
    return messages;
  }

  const combinedUserContent = systemMessages.join('\n\n') + (userMessages.length > 0 ? '\n\n' + userMessages.join('\n\n') : '');

  return [{ role: 'user', content: combinedUserContent }];
}

/**
 * OpenRouter API client with timeout, retries, and fallback keys
 */
export async function callOpenRouter(
  request: OpenRouterRequest,
  options: OpenRouterCallOptions = {}
): Promise<OpenRouterResponse> {
  const {
    timeout = 30000, // 30 seconds default
    maxRetries = 2,
    userId,
    topicId,
    traceId = `trace-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
  } = options;

  const model = request.model || process.env.OPENROUTER_MODEL || 'openai/gpt-4o-mini';
  const url = process.env.OPENROUTER_URL || 'https://openrouter.ai/api/v1/chat/completions';

  const adaptedMessages = adaptMessagesForModel(request.messages, model);
  const adaptedRequest = { ...request, messages: adaptedMessages };

  if (shouldRemoveJsonMode(model) && adaptedRequest.response_format) {
    delete adaptedRequest.response_format;
  }

  // Get all available API keys (primary + backups)
  const primary = (process.env.OPENROUTER_API_KEY || '').trim();
  const backups = (process.env.OPENROUTER_BACKUP_API_KEYS || '')
    .split(',')
    .map((s) => s.trim())
    .filter(Boolean);
  const allKeys = [primary, ...backups].filter(Boolean);

  if (allKeys.length === 0) {
    throw new Error('AI_GENERATION_FAILED: No OpenRouter API keys configured');
  }

  let lastError: Error | null = null;

  // Try each API key
  for (const apiKey of allKeys) {
    // Retry logic for each key
    for (let attempt = 0; attempt <= maxRetries; attempt++) {
      try {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), timeout);

        const logContext = {
          traceId,
          userId,
          topicId,
          attempt: attempt + 1,
          maxRetries: maxRetries + 1,
          keyIndex: allKeys.indexOf(apiKey) + 1,
          model,
        };

        console.log(`[OpenRouter] Request started`, logContext);

        const response = await fetch(url, {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json',
            'HTTP-Referer': process.env.OPENROUTER_REFERER || 'https://studycod.app',
            'X-Title': 'StudyCod Task Generator',
          },
          body: JSON.stringify({
            ...adaptedRequest,
            model,
          }),
          signal: controller.signal,
        });

        clearTimeout(timeoutId);

        if (!response.ok) {
          const errorText = await response.text();
          const error = new Error(`OpenRouter HTTP ${response.status}: ${errorText}`);
          console.error(`[OpenRouter] Request failed`, { ...logContext, status: response.status, error: errorText });
          
          let parsedError: any = null;
          try {
            parsedError = JSON.parse(errorText);
          } catch {
            parsedError = null;
          }

          const errorMessage = parsedError?.error?.message || errorText;
          const isInvalidArgument = response.status === 400 && (
            errorMessage.includes('INVALID_ARGUMENT') || 
            errorMessage.includes('Developer instruction is not enabled') ||
            errorMessage.includes('JSON mode is not enabled') ||
            errorMessage.includes('not enabled')
          );

          const isRateLimit = response.status === 429 || 
                             errorMessage.includes('rate limit') || 
                             errorMessage.includes('rate-limited') ||
                             errorMessage.toLowerCase().includes('temporarily rate-limited');

          if (isInvalidArgument) {
            throw new Error(`AI_GENERATION_FAILED: Invalid request for model ${model}. ${errorText}`);
          }
          
          if (response.status === 400) {
            throw new Error(`AI_GENERATION_FAILED: Invalid request for model ${model}. ${errorText}`);
          }
          
          if (response.status === 401 || response.status === 403) {
            lastError = error;
            break;
          }
          
          if (isRateLimit || response.status >= 500) {
            if (attempt < maxRetries) {
              lastError = error;
              const delay = Math.min(1000 * Math.pow(2, attempt), 5000);
              console.log(`[OpenRouter] Retrying after ${delay}ms`, { traceId, userId, topicId, attempt: attempt + 1, status: response.status });
              await new Promise((resolve) => setTimeout(resolve, delay));
              continue;
            }
            lastError = error;
            if (isRateLimit) {
              throw new Error(`AI_GENERATION_FAILED: Rate limit exceeded for model ${model}. ${errorText}`);
            }
          }
          
          throw error;
        }

        const data = await response.json() as OpenRouterResponse;

        if (data.error) {
          const errorMessage = data.error.message || data.error.type || 'Unknown error';
          const isInvalidArgument = errorMessage.includes('INVALID_ARGUMENT') || 
                                    errorMessage.includes('Developer instruction is not enabled') ||
                                    errorMessage.includes('JSON mode is not enabled') ||
                                    errorMessage.includes('not enabled');
          const isRateLimit = errorMessage.includes('rate limit') || 
                             errorMessage.includes('rate-limited') ||
                             errorMessage.includes('429') ||
                             errorMessage.toLowerCase().includes('temporarily rate-limited');
          
          const error = new Error(`OpenRouter API error: ${errorMessage}`);
          console.error(`[OpenRouter] API error`, { ...logContext, error: data.error });
          
          if (isInvalidArgument) {
            throw new Error(`AI_GENERATION_FAILED: Invalid request for model ${model}. ${errorMessage}`);
          }
          
          if (isRateLimit) {
            if (attempt < maxRetries) {
              lastError = error;
              const delay = Math.min(1000 * Math.pow(2, attempt), 5000);
              console.log(`[OpenRouter] Retrying after ${delay}ms (rate limit)`, { traceId, userId, topicId, attempt: attempt + 1 });
              await new Promise((resolve) => setTimeout(resolve, delay));
              continue;
            }
            throw new Error(`AI_GENERATION_FAILED: Rate limit exceeded for model ${model}. ${errorMessage}`);
          }
          
          if (attempt < maxRetries) {
            lastError = error;
            continue;
          }
          
          throw error;
        }

        const responseId = data.id || 'unknown';
        console.log(`[OpenRouter] Request succeeded`, { ...logContext, responseId });

        return data;
      } catch (err: any) {
        lastError = err;
        
        if (err.name === 'AbortError' || err.message?.includes('timeout')) {
          console.error(`[OpenRouter] Request timeout`, { traceId, userId, topicId, attempt: attempt + 1 });
          throw new Error('AI_GENERATION_FAILED: Request timeout (30s exceeded)');
        }

        if (err.message?.includes('Invalid request for model')) {
          throw err;
        }

        if (err.message?.includes('Rate limit exceeded')) {
          throw err;
        }

        if (err.message?.includes('AI_GENERATION_FAILED')) {
          throw err;
        }

        if (attempt >= maxRetries) {
          break;
        }

        const delay = Math.min(1000 * Math.pow(2, attempt), 5000);
        console.log(`[OpenRouter] Retrying after ${delay}ms`, { traceId, userId, topicId, attempt: attempt + 1 });
        await new Promise((resolve) => setTimeout(resolve, delay));
      }
    }
  }

  if (lastError?.message?.includes('Invalid request for model')) {
    throw lastError;
  }

  if (lastError?.message?.includes('Rate limit exceeded')) {
    throw lastError;
  }

  throw new Error(`AI_GENERATION_FAILED: All API keys exhausted. Last error: ${lastError?.message || 'Unknown error'}`);
}

